{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6522781d",
   "metadata": {},
   "source": [
    "Visualizing Data using t-SNE: https://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf\n",
    "\n",
    "Copyright (C) 2023, Zhao Bingqiang, All Rights Reserved\n",
    "\n",
    "Email: zbqherb@163.com\n",
    "\n",
    "2023-07-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7c27e",
   "metadata": {},
   "source": [
    "# Load Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57328106-567d-4be0-a0bc-1a20e88ceb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import umap.plot\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500ea23-53d8-4421-92f6-647d41e34d80",
   "metadata": {},
   "source": [
    "## Image data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562b97f-9a4a-4729-b238-4acb2e77e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID-19 CT\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(512),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize(1000),\n",
    "                                     transforms.CenterCrop(512),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f48247-4ad9-4e69-99de-48f4eff9bc5f",
   "metadata": {},
   "source": [
    "## Load `trained model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541084de-8fed-4af0-84f6-1302f38a9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('checkpoint/best-0.971.pth')\n",
    "model = model.eval().to(device)\n",
    "\n",
    "# Extract output results of the middle layer  as semantic features and Calculate semantic features of single image\n",
    "model_trunc = create_feature_extractor(model, return_nodes={'avgpool': 'semantic_feature'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d681eb-d2af-4e54-bfa2-78590dffafbe",
   "metadata": {},
   "source": [
    "## Load `test_dataset prediction results.csv` and Calculate semantic features of each image in the test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb76734-83d2-49c9-ae35-3240595d5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('table/test_dataset prediction results.csv')\n",
    "encoding_array = []\n",
    "img_path_list = []\n",
    "\n",
    "for img_path in tqdm(df['Data Path']):\n",
    "    img_path_list.append(img_path)\n",
    "    img_pil = Image.open(img_path).convert('RGB')\n",
    "    input_img = test_transform(img_pil).unsqueeze(0).to(device) \n",
    "    # forward prediction to obtain the output of the avgpool layer\n",
    "    feature = model_trunc(input_img)['semantic_feature'].squeeze().detach().cpu().numpy() \n",
    "    encoding_array.append(feature)\n",
    "    \n",
    "encoding_array = np.array(encoding_array)\n",
    "np.save('table/test_dataset semantic features.npy', encoding_array)\n",
    "encoding_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12407a50",
   "metadata": {},
   "source": [
    "# Visualization setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_list = ['.', ',', 'o', 'v', '^', '<', '>', '1', '2', '3', '4', '8', 's', 'p', 'P', '*', 'h', 'H', '+', 'x', 'X', 'D', 'd', '|', '_', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "class_list = np.unique(df['Label Name'])\n",
    "n_class = len(class_list) # test_dataset ID number\n",
    "palette = sns.hls_palette(n_class) \n",
    "\n",
    "# Randomly shuffle the color list and dot type list\n",
    "random.seed(1234)\n",
    "random.shuffle(marker_list)\n",
    "random.shuffle(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623eeb24",
   "metadata": {},
   "source": [
    "## t-SNE 2D visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2, n_iter = 20000)\n",
    "X_tsne_2d = tsne.fit_transform(encoding_array)\n",
    "\n",
    "show_feature = 'Label Name'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.figure(figsize = (15, 15))\n",
    "for idx, image in enumerate(class_list): # Scanning each class\n",
    "\n",
    "    color = palette[idx]\n",
    "    marker = marker_list[idx%len(marker_list)]\n",
    "\n",
    "    # Find the index number of all images labeled as the current class\n",
    "    indices = np.where(df[show_feature] == image)\n",
    "    plt.scatter(X_tsne_2d[indices, 0], X_tsne_2d[indices, 1], color = color, marker = marker, label = image, s = 150)\n",
    "\n",
    "plt.legend(fontsize = 16, markerscale = 1, bbox_to_anchor = (1, 1), frameon = False)\n",
    "plt.xlabel('t-SNE 1st component', fontsize = 20)\n",
    "plt.ylabel('t-SNE 2nd component', fontsize = 20)\n",
    "plt.savefig('figure/t-SNE.tif', dpi = 300, bbox_inches = 'tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9bea7",
   "metadata": {},
   "source": [
    "## t-SNE `plotply` 2D interactive visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2d = pd.DataFrame()\n",
    "df_2d['t-SNE 1st component'] = list(X_tsne_2d[:, 0].squeeze())\n",
    "df_2d['t-SNE 2nd component'] = list(X_tsne_2d[:, 1].squeeze())\n",
    "df_2d['Label Name'] = df['Label Name']\n",
    "df_2d['Predicted Class'] = df['top-1 Predicted Name']\n",
    "df_2d['Data Path'] = df['Data Path']\n",
    "df_2d.to_csv('table/t-SNE-2D.csv', index = False)\n",
    "\n",
    "fig = px.scatter(df_2d, \n",
    "                 x = 't-SNE 1st component', \n",
    "                 y = 't-SNE 2nd component',\n",
    "                 color = show_feature, \n",
    "                 labels = show_feature,\n",
    "                 symbol = show_feature, \n",
    "                 hover_name = 'Data Path',\n",
    "                 opacity = 0.8,\n",
    "                 width = 1000, \n",
    "                 height = 1000\n",
    "                )\n",
    "# Layout set\n",
    "fig.update_layout(margin = dict(l = 0, r = 0, b = 0, t = 0))\n",
    "fig.show()\n",
    "fig.write_html('figure/t-SNE 2D.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca17bf",
   "metadata": {},
   "source": [
    "## t-SNE 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 3, n_iter = 20000)\n",
    "X_tsne_3d = tsne.fit_transform(encoding_array)\n",
    "\n",
    "show_feature = 'Label Name'\n",
    "\n",
    "df_3d = pd.DataFrame()\n",
    "df_3d['t-SNE 1st component'] = list(X_tsne_3d[:, 0].squeeze())\n",
    "df_3d['t-SNE 2nd component'] = list(X_tsne_3d[:, 1].squeeze())\n",
    "df_3d['t-SNE 3rd component'] = list(X_tsne_3d[:, 2].squeeze())\n",
    "df_3d['Label Name'] = df['Label Name']\n",
    "df_3d['Predicted Class'] = df['top-1 Predicted Name']\n",
    "df_3d['Data Path'] = df['Data Path']\n",
    "df_3d.to_csv('table/t-SNE-3D.csv', index = False)\n",
    "\n",
    "fig = px.scatter_3d(df_3d, \n",
    "                    x = 't-SNE 1st component', \n",
    "                    y = 't-SNE 2nd component', \n",
    "                    z = 't-SNE 3rd component',\n",
    "                    color = show_feature, \n",
    "                    labels = show_feature,\n",
    "                    symbol = show_feature, \n",
    "                    hover_name = 'Data Path',\n",
    "                    opacity = 0.6,\n",
    "                    width = 1000, \n",
    "                    height = 1000)\n",
    "\n",
    "fig.update_layout(margin=dict(l = 0, r = 0, b = 0, t = 0))\n",
    "fig.show()\n",
    "fig.write_html('figure/t-SNE 3D.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageClassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
